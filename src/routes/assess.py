# import shutil
# from transformers import TRANSFORMERS_CACHE

# # Delete the cache directory
# shutil.rmtree(TRANSFORMERS_CACHE, ignore_errors=True)


# import torch

# # Clear PyTorch cache
# torch.cuda.empty_cache()



